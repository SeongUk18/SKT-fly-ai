{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506},"id":"3jWksotyRNVO","outputId":"468f56df-c8be-48c1-f2c3-eb50914046d3","executionInfo":{"status":"ok","timestamp":1721272429086,"user_tz":-540,"elapsed":7726,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym[accept_rom_license,atari,toy_text] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","\u001b[33mWARNING: gym 0.25.2 does not provide the extra 'accept_rom_license'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept_rom_license,atari,toy_text]) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept_rom_license,atari,toy_text]) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept_rom_license,atari,toy_text]) (0.0.8)\n","Collecting ale-py~=0.7.5 (from gym[accept_rom_license,atari,toy_text])\n","  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygame==2.1.0 (from gym[accept_rom_license,atari,toy_text])\n","  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[accept_rom_license,atari,toy_text]) (6.4.0)\n","Installing collected packages: pygame, ale-py\n","  Attempting uninstall: pygame\n","    Found existing installation: pygame 2.6.0\n","    Uninstalling pygame-2.6.0:\n","      Successfully uninstalled pygame-2.6.0\n","Successfully installed ale-py-0.7.5 pygame-2.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gym"]},"id":"dd626736f2bb47508e6df9de3726a296"}},"metadata":{}}],"source":["!pip install gym[atari,toy_text,accept_rom_license]"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"M6dN2WFTRbdp","executionInfo":{"status":"ok","timestamp":1721272444136,"user_tz":-540,"elapsed":1181,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["import numpy as np\n","import random\n","import gym\n","env = gym.make('Taxi-v3', new_step_api=True)\n","\n","# step types\n","STEPTYPE_FIRST = 0\n","STEPTYPE_MID = 1\n","STEPTYPE_LAST = 2\n","\n","Q = np.random.uniform(size=(500, 6))"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9L64PFbVwpw","outputId":"2bd7c5c9-69ff-4a8a-d5ac-ff9eb423694d","executionInfo":{"status":"ok","timestamp":1721272445457,"user_tz":-540,"elapsed":2,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"execute_result","data":{"text/plain":["91"]},"metadata":{},"execution_count":2}],"source":["env.reset()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"073H-qavVy4n","outputId":"e8174e78-4f53-4b23-e383-d1c21993d31d","executionInfo":{"status":"ok","timestamp":1721272446313,"user_tz":-540,"elapsed":2,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]},{"output_type":"execute_result","data":{"text/plain":["(191,\n"," -1,\n"," False,\n"," False,\n"," {'prob': 1.0, 'action_mask': array([1, 1, 0, 1, 0, 0], dtype=int8)})"]},"metadata":{},"execution_count":3}],"source":["env.step(0)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ca9TbK-_TBur","executionInfo":{"status":"ok","timestamp":1721272449576,"user_tz":-540,"elapsed":1,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["# wrapper for gym's blackjack environment\n","def generate_start_step():\n","    return { 'observation': env.reset(), 'reward': 0., 'step_type': STEPTYPE_FIRST }\n","\n","def generate_next_step(step, action):\n","    obs, reward, done, _, info = env.step(action)\n","    step_type = STEPTYPE_LAST if done else STEPTYPE_MID\n","    return { 'observation': obs, 'reward': reward, 'step_type': step_type }"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TEU1Bs_LU0mH","executionInfo":{"status":"ok","timestamp":1721272525400,"user_tz":-540,"elapsed":633,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["epsilon = 0.1\n","\n","def get_eps_soft_action(step):\n","    # epsilon-soft greedy policy\n","    if random.uniform(0, 1) < epsilon:\n","        # epsilon 확률로 무작위 행동 선택\n","        return env.action_space.sample()\n","    else:\n","        # (1 - epsilon) 확률로 Q 값이 가장 큰 행동 선택\n","        observation = step['observation']\n","        return np.argmax(Q[observation])\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"cmFs6E6xTHKB","executionInfo":{"status":"ok","timestamp":1721272529738,"user_tz":-540,"elapsed":1027,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["def get_greedy_action(step):\n","    observ = step['observation']\n","    return np.argmax(Q[observ])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"YvastGlsTJG0","executionInfo":{"status":"ok","timestamp":1721272531076,"user_tz":-540,"elapsed":1,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["def get_random_action(step):\n","    return random.randint(0, env.action_space.n-1)\n","\n","behavior_prob_hit = 1. / float(env.action_space.n)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OGwGb5S9TK7N","executionInfo":{"status":"ok","timestamp":1721272531077,"user_tz":-540,"elapsed":2,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["# return true if (observ, action) exists in epi\n","def in_episode(epi, observ, action):\n","    for s, a in zip(*epi):\n","        if s['observation'] == observ and a == action:\n","            return True\n","    return False"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"I0GCIFYETMtH","executionInfo":{"status":"ok","timestamp":1721272531735,"user_tz":-540,"elapsed":2,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["def generate_episode(policy_func=get_random_action):\n","    episode = list()\n","    actions = list()\n","    frames = list()\n","    step = generate_start_step()\n","    frames.append(env.render(mode='ansi'))\n","    episode.append(step)\n","    while step['step_type'] != STEPTYPE_LAST:\n","        action = policy_func(step)\n","        step = generate_next_step(step, action)\n","        frames.append(env.render(mode='ansi'))\n","        episode.append(step)\n","        actions.append(action)\n","    return episode, actions, frames"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6VTajme1TOB3","executionInfo":{"status":"ok","timestamp":1721272532913,"user_tz":-540,"elapsed":2,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["from IPython.display import clear_output\n","from time import sleep\n","\n","def print_frames(frames):\n","    for i, frame in enumerate(frames):\n","        clear_output(wait=True)\n","        print(frame)\n","        sleep(.2)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"tzTtqQVwTmP2","executionInfo":{"status":"ok","timestamp":1721272654734,"user_tz":-540,"elapsed":120487,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[],"source":["maxiter = 100000\n","gamma = 1\n","epsilon = 0.3\n","lr_rate = 0.8\n","\n","Q = np.random.uniform(size=(env.observation_space.n, env.action_space.n))\n","\n","for _ in range(maxiter):\n","    # starting step\n","    step = generate_start_step()\n","    action = get_random_action(step)\n","    done = False\n","    while not done:\n","        next_step = generate_next_step(step, action)\n","\n","        if next_step['step_type'] == STEPTYPE_LAST:\n","            state = step['observation']\n","            idx1 = (state, action)\n","            Q[idx1] = Q[idx1] + lr_rate * (next_step['reward'] - Q[idx1])\n","            done = True\n","        else:\n","            best_action = get_greedy_action(next_step)\n","\n","            state = step['observation']\n","            next_state = next_step['observation']\n","            idx1 = (state, action)\n","            idx2 = (next_state, best_action)\n","            Q[idx1] = Q[idx1] + lr_rate * ((next_step['reward'] + gamma * Q[idx2]) - Q[idx1])\n","\n","            next_action = get_eps_soft_action(step)\n","\n","            step = next_step\n","            action = next_action\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUwSbyvZWLyn","outputId":"f4feaf42-d622-424d-b919-d77371cb475f","executionInfo":{"status":"ok","timestamp":1721272747054,"user_tz":-540,"elapsed":3966,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (Dropoff)\n","\n"]}],"source":["epi, actions, frames = generate_episode(policy_func=get_greedy_action)\n","print_frames(frames)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kvOoPvwfURYX","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"ok","timestamp":1721277597601,"user_tz":-540,"elapsed":13910,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}},"outputId":"0f408c0e-785b-484a-831f-bd74a5eef356"},"outputs":[{"output_type":"stream","name":"stdout","text":["o  o  o  o  o  o  o  o  o  o  o  o\n","o  o  o  o  o  o  o  o  o  o  o  o\n","o  o  o  o  o  o  o  o  o  o  o  o\n","o  C  C  C  C  C  C  C  C  C  C  x\n","\n","\n","Timestep: 13\n","State: 35\n","Action: 2\n","Reward: -1\n"]}],"source":["import numpy as np\n","import random\n","import gym\n","from gym.envs.toy_text.cliffwalking import CliffWalkingEnv\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","import time\n","\n","env = CliffWalkingEnv()\n","\n","# step types\n","STEPTYPE_FIRST = 0\n","STEPTYPE_MID = 1\n","STEPTYPE_LAST = 2\n","\n","Q = np.random.uniform(size=(env.observation_space.n, env.action_space.n))\n","\n","def generate_start_step():\n","    return {'observation': env.reset(), 'reward': 0., 'step_type': STEPTYPE_FIRST}\n","\n","def generate_next_step(step, action):\n","    obs, reward, done, _, info = env.step(action)\n","    step_type = STEPTYPE_LAST if done else STEPTYPE_MID\n","    return {'observation': obs, 'reward': reward, 'step_type': step_type}\n","\n","epsilon = 0.1\n","\n","def get_eps_soft_action(step):\n","    if random.uniform(0, 1) < epsilon:\n","        return env.action_space.sample()\n","    else:\n","        observation = step['observation']\n","        return np.argmax(Q[observation])\n","\n","def get_greedy_action(state):\n","    return np.argmax(Q[state])\n","\n","def generate_episode(policy_func):\n","    step = generate_start_step()\n","    frames = []\n","    done = False\n","\n","    while not done:\n","        state = step['observation']\n","        action = policy_func(state)\n","        next_step = generate_next_step(step, action)\n","\n","        frames.append({\n","            'frame': env.render(mode='ansi'),\n","            'state': state,\n","            'action': action,\n","            'reward': next_step['reward']\n","        })\n","\n","        step = next_step\n","        done = next_step['step_type'] == STEPTYPE_LAST\n","\n","    return frames\n","\n","def print_frames(frames):\n","    for i, frame_info in enumerate(frames):\n","        clear_output(wait=True)\n","        print(frame_info['frame'])\n","        print(f\"Timestep: {i+1}\")\n","        print(f\"State: {frame_info['state']}\")\n","        print(f\"Action: {frame_info['action']}\")\n","        print(f\"Reward: {frame_info['reward']}\")\n","        time.sleep(1)\n","\n","# Hyperparameters\n","lr_rate = 0.1\n","gamma = 0.99\n","\n","# Training Q-learning\n","num_episodes = 500\n","reward_per_episode = []\n","\n","for episode in range(num_episodes):\n","    step = generate_start_step()\n","    done = False\n","    total_reward = 0\n","\n","    while not done:\n","        action = get_eps_soft_action(step)\n","        next_step = generate_next_step(step, action)\n","\n","        state = step['observation']\n","        next_state = next_step['observation']\n","        reward = next_step['reward']\n","        done = next_step['step_type'] == STEPTYPE_LAST\n","\n","        best_action = np.argmax(Q[next_state])\n","        Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * Q[next_state, best_action] - Q[state, action])\n","\n","        step = next_step\n","        total_reward += reward\n","\n","    reward_per_episode.append(total_reward)\n","\n","print(\"Training completed\")\n","\n","# Plotting the training progress\n","plt.plot(reward_per_episode)\n","plt.xlabel('Episode')\n","plt.ylabel('Total Reward')\n","plt.title('Total Reward per Episode during Training')\n","plt.show()\n","\n","# Generate and print frames for a sample episode\n"]},{"cell_type":"code","source":["frames = generate_episode(policy_func=get_greedy_action)\n","print_frames(frames)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"meeqSd-QJE3s","executionInfo":{"status":"ok","timestamp":1721277647118,"user_tz":-540,"elapsed":13447,"user":{"displayName":"SeongUk Han","userId":"03035106719121349200"}},"outputId":"0a65f19f-c2c1-401d-abb6-a6a23e83b9eb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["o  o  o  o  o  o  o  o  o  o  o  o\n","o  o  o  o  o  o  o  o  o  o  o  o\n","o  o  o  o  o  o  o  o  o  o  o  o\n","o  C  C  C  C  C  C  C  C  C  C  x\n","\n","\n","Timestep: 13\n","State: 35\n","Action: 2\n","Reward: -1\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}