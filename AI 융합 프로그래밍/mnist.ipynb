{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc9716c-9a88-435b-b799-9828ce581419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\skt25\\anaconda3\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.1 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\skt25\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b12a1f-7139-4585-9998-0794822af504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365973b7-265e-4cf0-a92b-0eb15dcc3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import requests\n",
    "\n",
    "download_root = '../chap02/data/MNIST_DATASET'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform = mnist_transform, train= True, download=True)\n",
    "\n",
    "valid_dataset = MNIST(download_root, transform = mnist_transform, train= False, download=True)\n",
    "\n",
    "test_dataset = MNIST(download_root, transform = mnist_transform, train= False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e53b5b-54f8-4c58-b47a-73e9cbc5c727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../chap02/data/MNIST_DATASET\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(1.0,))\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89ff4cf-008f-418b-877f-4467fbb31c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3711fb-48ef-48fc-972b-60f59b58c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2739e2a-52ff-43f4-9454-078046674b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp39-cp39-win_amd64.whl.metadata (165 kB)\n",
      "     ---------------------------------------- 0.0/165.9 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 30.7/165.9 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------  163.8/165.9 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 165.9/165.9 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\skt25\\anaconda3\\envs\\torch_book\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\skt25\\anaconda3\\envs\\torch_book\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\skt25\\anaconda3\\envs\\torch_book\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\skt25\\anaconda3\\envs\\torch_book\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\skt25\\anaconda3\\envs\\torch_book\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\skt25\\anaconda3\\envs\\torch_book\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.1-cp39-cp39-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/8.0 MB 12.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.4/8.0 MB 14.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.9/8.0 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.7/8.0 MB 14.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.5/8.0 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/8.0 MB 16.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/8.0 MB 16.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/8.0 MB 16.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/8.0 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.5/8.0 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.4/8.0 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.4/8.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.9/8.0 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp39-cp39-win_amd64.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.8/182.8 kB 10.8 MB/s eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.2/2.2 MB 36.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 19.9 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.2/56.2 kB ? eta 0:00:00\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.9.1 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dca4039-1402-4e99-873c-692b0fe4430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abac0e40-03d0-4443-89d1-fcce1a59f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../chap05/data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../chap05/data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../chap05/data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../chap05/data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../chap05/data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(\"../chap05/data\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\"../chap05/data\", download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a6ef40-0d60-48c6-82e9-f601464c3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f3bbdd-9a21-4594-96c2-2497df2badd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1f6337-7ae6-450c-ada7-ca28d8739053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        out = input_data.view(-1, 784)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d3f0a51-d880-44e0-a6ff-4436470d0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionDNN(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001;\n",
    "model = FashionDNN();\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate);\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a38d919-cf9d-464b-8e7e-3344fa56dcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.6281203627586365, Accuracy: 83.1199951171875%\n",
      "Iteration: 1000, Loss: 0.4296606183052063, Accuracy: 84.80999755859375%\n",
      "Iteration: 1500, Loss: 0.36627623438835144, Accuracy: 83.87999725341797%\n",
      "Iteration: 2000, Loss: 0.41814789175987244, Accuracy: 85.18999481201172%\n",
      "Iteration: 2500, Loss: 0.2955018877983093, Accuracy: 86.30999755859375%\n",
      "Iteration: 3000, Loss: 0.3149814009666443, Accuracy: 86.27999877929688%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        train = images.view(100, 1, 28, 28)\n",
    "        labels = labels\n",
    "        \n",
    "        outputs = model(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "    \n",
    "        if not (count % 50):    \n",
    "            total = 0\n",
    "            correct = 0        \n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)            \n",
    "                test = images.view(100, 1, 28, 28)        \n",
    "                outputs = model(test)            \n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()            \n",
    "                total += len(labels)\n",
    "            \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        \n",
    "        if not (count % 500):\n",
    "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d48ed-8d6a-4dc2-b71e-e5888cef1e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
